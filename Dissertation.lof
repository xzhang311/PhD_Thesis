\contentsline {figure}{\numberline {1.1}{\ignorespaces A screen-shot of street view point cloud data used in my research. There are 9195492 points that are contained in this scene.}}{3}
\contentsline {figure}{\numberline {1.2}{\ignorespaces A demonstration of using synthetic template to simulate edge image of roofs used in my research.}}{4}
\contentsline {figure}{\numberline {2.1}{\ignorespaces Examples of (a) real roof edge vs. corresponding (b) synthetic roof edge images. The synthetic data is generated by the algorithms in Sec. 4. The examples are randomly drawn from SRC dataset.}}{15}
\contentsline {figure}{\numberline {2.2}{\ignorespaces An example of input polygon vertices, cutting lines and six segmented components result.}}{18}
\contentsline {figure}{\numberline {2.3}{\ignorespaces An example of segmentation on a complex building roof. All pieces are normalize to a same dimension.}}{19}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Examples of roof top images used in my work.}}{20}
\contentsline {figure}{\numberline {2.5}{\ignorespaces For five roof styles used in my work, control points of each style are given in above figures which are shown as blue dots.}}{21}
\contentsline {figure}{\numberline {2.6}{\ignorespaces For five roof styles used in my work, control points of each style are given in above figures which are shown as blue dots.}}{21}
\contentsline {figure}{\numberline {2.7}{\ignorespaces Root images of all kinds of digit characters.}}{25}
\contentsline {figure}{\numberline {2.8}{\ignorespaces Illustrations of the migration of control points and intermediate synthetic images generated using control points in each step. The distance transform images of the synthetic prototype and real images are shown as the left most and right most images respectively.}}{26}
\contentsline {figure}{\numberline {2.9}{\ignorespaces Illustrations of the migration of control points for character 4. The control points are migrated from root image (blue) to destination image (red) and arrows are used to indicate points moving direction.}}{27}
\contentsline {figure}{\numberline {2.10}{\ignorespaces Detailed schematic of a LSTM memory block as used in the hidden layers of a recurrent neural network. The figure is originally from \cite {greff2016lstm}.}}{29}
\contentsline {figure}{\numberline {2.11}{\ignorespaces Network structure of the proposed text to image synthesis approach. The notation G represents generator and notation D represents discriminator.}}{31}
\contentsline {figure}{\numberline {2.12}{\ignorespaces Comparison of image synthesis results using different input sentence features using network structure described in \cite {reed2016generative}}}{32}
\contentsline {figure}{\numberline {2.13}{\ignorespaces Examples of synthesized flower images. Please notice how each synthesized images correspond to works in description.}}{45}
\contentsline {figure}{\numberline {2.14}{\ignorespaces Illustration of all semantic points used in my work, red sphere on each roof represent the typical location of semantic point, the color bar under each image correspond to all color labels used in previous demo.}}{46}
\contentsline {figure}{\numberline {2.15}{\ignorespaces Roof styles I classified in \cite {ZX:14}. From top to down, left to right: flat, shed, gable, hip, pyramid, curve, gambrel, mansard, hex and dome.}}{46}
\contentsline {figure}{\numberline {2.16}{\ignorespaces Illustration of erosion in my data. Three different levels of filtering are applied to each roof. In total, including original version, four versions are used in my work.}}{47}
\contentsline {figure}{\numberline {2.17}{\ignorespaces Illustration of all roof base models that are used in this work.}}{47}
\contentsline {figure}{\numberline {2.18}{\ignorespaces Illustration of network structure used in the proposed unsupervised optical flow learning neural network. Parts in red dash frame are novel contribution of my work.}}{48}
\contentsline {figure}{\numberline {2.19}{\ignorespaces Results of image transformation using predicted optical flows. Images are grouped in three rows each. In each group, a pair of images inputted to network are in first row and third row. Results of using optical flow to transform first row images are given in second row.}}{49}
\contentsline {figure}{\numberline {2.20}{\ignorespaces Examples of pairs of images used as input of the proposed network and automatically generated masks are shown in this figure. }}{50}
\contentsline {figure}{\numberline {2.21}{\ignorespaces Comaprison of optical flows.}}{51}
\contentsline {figure}{\numberline {3.1}{\ignorespaces An example of actual roof edge image and corresponding synthetic roof edge image in my work \cite {ZX14} is shown in above figures.}}{52}
\contentsline {figure}{\numberline {3.2}{\ignorespaces The schema of perturbation-based recognition of \cite {Comput.Sci.&Appl.Math.1997} is shown above.}}{54}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Illustration of HOR feature.}}{56}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Computing edge orientation in the binary template image.}}{61}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Example of the modified distance measure. In both cases I use a neighborhood of size $p=13$, and select the lowest $q=5$ neighbors. While the distance at the pixel is the same (1.5), the modified distance measure in the bottom example is higher due to the larger distance to neighbors.}}{62}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Results of matching partially occluded buildings. (a) Edge images detected from target image. (b)-(d) Results of the CM algorithm, the results of the DCM algorithm and the results of the proposed algorithm, respectively. (e) The pixels selected for computing the average error during the matching process.}}{65}
\contentsline {figure}{\numberline {3.7}{\ignorespaces Experimental evaluation results on the San Francisco (upper row) and Chicago (lower row) datasets. The left and right columns show different evaluation metrics.}}{66}
\contentsline {figure}{\numberline {3.8}{\ignorespaces Illustration of the frame I used in the computation of the shape distribution features.}}{69}
\contentsline {figure}{\numberline {3.9}{\ignorespaces Example of applying Gaussian smoothing to the spin image features. (a) The red dot shows the location where spin image features are computed. (b) Generated spin image without smoothing. (c) Result of spin image after random disruption.}}{70}
\contentsline {figure}{\numberline {3.10}{\ignorespaces Illustration of distribution of bumpiness at points with different slope.}}{71}
\contentsline {figure}{\numberline {3.11}{\ignorespaces Illustration of the histogram $H$ and the quadratic function fitted on it.}}{72}
\contentsline {figure}{\numberline {3.12}{\ignorespaces Point classification results obtained by running my point type classifier on dataset one (top row) and the dataset two (bottom row). The colors of points corresponds to the color bars of the point in Figure 2.16\hbox {}.}}{73}
\contentsline {figure}{\numberline {3.13}{\ignorespaces The distribution of the roof styles in the two datasets.}}{74}
\contentsline {figure}{\numberline {3.14}{\ignorespaces The comparison of F-Score on the two datasets by running KM, GMM and the proposed approach.}}{76}
\contentsline {figure}{\numberline {3.15}{\ignorespaces The confusion matrix of obtained by the proposed approach on two datasets.}}{77}
\contentsline {figure}{\numberline {3.16}{\ignorespaces The F-Score of each roof style obtained by using an increasing proportion of the training data.}}{77}
\contentsline {figure}{\numberline {4.1}{\ignorespaces t-SNE visulization of synthetic gap using the data from SRC dataset. (a) synthetic gap of real and synthetic data; (b) MCAE bridges the synthetic gap.}}{78}
\contentsline {figure}{\numberline {4.2}{\ignorespaces (a) Illustration of the proposed MCAE model in a stacked autoencoder structure, where black edge between two layers are linked to and shared by two tasks, red and blue links are separately connected to left and right task respectively. (b) A zoom in structure of MCAE. }}{83}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Examples of images before and after being reconstructed by MCAE. It could be observed from the images that actual images and synthetic images look much more similar after being processed by MCAE.}}{89}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Correlation between real and corresponding best matching \textit {Syn I} data.}}{89}
\contentsline {figure}{\numberline {4.5}{\ignorespaces t-SNE \cite {tsne} visualization of synthetic gap bridged by MCAE. (a) Data distributions of each class of SRC dataset. For many data instances, the (circle) real and (dot points) synthetic data are not overlapping. This is synthetic gap. (b) Data distributions of the reconstructed images by MCAE for each class of SRC dataset. The reconstructed images of all the real (circle) and synthetic (dot points) are almost overlapped. It means that my MCAE can bridge the synthetic gap.}}{90}
\contentsline {figure}{\numberline {5.1}{\ignorespaces Demonstration of CGMOS. In first two figures, diamonds represent minority samples and circles represent majority samples. The positions of synthesized data points are labeled using a star symbol on a horizontal line passing through the center. The x and y axes represent features. In the bottom figure the x axis indicates a location where a sample was added (in correspondence with the first two figures) whereas the y-axis indicates the relative certainty change.}}{100}
\contentsline {figure}{\numberline {5.2}{\ignorespaces ROC curves of the artificial datasets classification results using b-kde classifier. In total, results of 6 datasets are shown in the above figures.}}{114}
\contentsline {figure}{\numberline {5.3}{\ignorespaces ROC curves of classification results. From left to right, up to down, we show the results of 6 different classifiers: b-kde, knn, svm, nn, rf and Adaboost.M1. Curves in blue are the results of the proposed CGMOS.}}{115}
\contentsline {figure}{\numberline {5.4}{\ignorespaces Comparison of results when increasing the number of data synthesized for the minority class. The curves measure the average AUC of the ROC curves. Curves in blue are the results of the proposed CGMOS.}}{116}
